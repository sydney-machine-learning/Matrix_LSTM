{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gzip\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def load_mnist(root):\n",
    "    # Load MNIST dataset for generating training data.\n",
    "    path = os.path.join(root, 'data', 'Moving_MNIST', 'train-images-idx3-ubyte.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        mnist = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        mnist = mnist.reshape(-1, 28, 28)\n",
    "    return mnist\n",
    "\n",
    "\n",
    "def load_fixed_set(root, is_train):\n",
    "    # Load the fixed dataset\n",
    "    filename = 'mnist_test_seq.npy'\n",
    "    path = os.path.join(root, 'data', 'Moving_MNIST', filename)\n",
    "    dataset = np.load(path)\n",
    "    dataset = dataset[..., np.newaxis]\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "images = load_mnist(root='../')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "idx = np.random.randint(60000)\n",
    "Image.fromarray(images[idx])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FB31AB32050>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nGNgGGSAEY0fbSlydDIWdanlVjN+/v337x4WuYl///349+/fv7dWGFI6s//8+/fv8ZPNU60x9WX9+/fvgYmwMDuyIAsSe8EZNB3IkjcZxIXfvcDinKx///59vHT3+b1Ll0qwSkLBDz+YIBOUfnoDro6tAsaCh5DkejOGTNnbukUMDM9kMAyWcnfnZ2DQev/v3ysxLI5iYGBgYNj479//DDQ7kcHvD3gkX62AMpADgVPo5xthDgaG9Vg02G7/92T6o3//Hmpgypm+g4TBn3AsGrWf/Pj779+/Z8kIIZRkkhyzl+HVLCwaqQsAuF5nDP/rV10AAAAASUVORK5CYII="
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class MovingMNIST(data.Dataset):\n",
    "    def __init__(self, root, is_train=True, n_frames_input=10, n_frames_output=10, num_objects=[2],\n",
    "                 transform=None):\n",
    "        '''\n",
    "        param num_objects: a list of number of possible objects.\n",
    "        '''\n",
    "        super(MovingMNIST, self).__init__()\n",
    "\n",
    "        self.dataset = None\n",
    "        if is_train:\n",
    "            self.mnist = load_mnist(root)\n",
    "        else:\n",
    "            if num_objects[0] != 2:\n",
    "                self.mnist = load_mnist(root)\n",
    "            else:\n",
    "                self.dataset = load_fixed_set(root, False)\n",
    "        self.length = int(1e4) if self.dataset is None else self.dataset.shape[1]\n",
    "\n",
    "        self.is_train = is_train\n",
    "        self.num_objects = num_objects\n",
    "        self.n_frames_input = n_frames_input\n",
    "        self.n_frames_output = n_frames_output\n",
    "        self.n_frames_total = self.n_frames_input + self.n_frames_output\n",
    "        self.transform = transform\n",
    "        # For generating data\n",
    "        self.image_size_ = 64\n",
    "        self.digit_size_ = 28\n",
    "        self.step_length_ = 0.1\n",
    "\n",
    "    def get_random_trajectory(self, seq_length):\n",
    "        ''' Generate a random sequence of a MNIST digit '''\n",
    "        canvas_size = self.image_size_ - self.digit_size_\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        theta = random.random() * 2 * np.pi\n",
    "        v_y = np.sin(theta)\n",
    "        v_x = np.cos(theta)\n",
    "\n",
    "        start_y = np.zeros(seq_length)\n",
    "        start_x = np.zeros(seq_length)\n",
    "        for i in range(seq_length):\n",
    "            # Take a step along velocity.\n",
    "            y += v_y * self.step_length_\n",
    "            x += v_x * self.step_length_\n",
    "\n",
    "            # Bounce off edges.\n",
    "            if x <= 0:\n",
    "                x = 0\n",
    "                v_x = -v_x\n",
    "            if x >= 1.0:\n",
    "                x = 1.0\n",
    "                v_x = -v_x\n",
    "            if y <= 0:\n",
    "                y = 0\n",
    "                v_y = -v_y\n",
    "            if y >= 1.0:\n",
    "                y = 1.0\n",
    "                v_y = -v_y\n",
    "            start_y[i] = y\n",
    "            start_x[i] = x\n",
    "\n",
    "        # Scale to the size of the canvas.\n",
    "        start_y = (canvas_size * start_y).astype(np.int32)\n",
    "        start_x = (canvas_size * start_x).astype(np.int32)\n",
    "        return start_y, start_x\n",
    "\n",
    "    def generate_moving_mnist(self, num_digits=2):\n",
    "        '''\n",
    "        Get random trajectories for the digits and generate a video.\n",
    "        '''\n",
    "        data = np.zeros((self.n_frames_total, self.image_size_, self.image_size_), dtype=np.float32)\n",
    "        for n in range(num_digits):\n",
    "            # Trajectory\n",
    "            start_y, start_x = self.get_random_trajectory(self.n_frames_total)\n",
    "            ind = random.randint(0, self.mnist.shape[0] - 1)\n",
    "            digit_image = self.mnist[ind]\n",
    "            for i in range(self.n_frames_total):\n",
    "                top = start_y[i]\n",
    "                left = start_x[i]\n",
    "                bottom = top + self.digit_size_\n",
    "                right = left + self.digit_size_\n",
    "                # Draw digit\n",
    "                data[i, top:bottom, left:right] = np.maximum(data[i, top:bottom, left:right], digit_image)\n",
    "\n",
    "        data = data[..., np.newaxis]\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        length = self.n_frames_input + self.n_frames_output\n",
    "        if self.is_train or self.num_objects[0] != 2:\n",
    "            # Sample number of objects\n",
    "            num_digits = random.choice(self.num_objects)\n",
    "            # Generate data on the fly\n",
    "            images = self.generate_moving_mnist(num_digits)\n",
    "        else:\n",
    "            images = self.dataset[:, idx, ...]\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     images = self.transform(images)\n",
    "\n",
    "        r = 1 # patch size (a 4 dans les PredRNN)\n",
    "        w = int(64 / r)\n",
    "        images = images.reshape((length, w, r, w, r)).transpose(0, 2, 4, 1, 3).reshape((length, r * r, w, w))\n",
    "\n",
    "        input = images[:self.n_frames_input]\n",
    "        if self.n_frames_output > 0:\n",
    "            output = images[self.n_frames_input:length]\n",
    "        else:\n",
    "            output = []\n",
    "\n",
    "        frozen = input[-1]\n",
    "        # add a wall to input data\n",
    "        # pad = np.zeros_like(input[:, 0])\n",
    "        # pad[:, 0] = 1\n",
    "        # pad[:, pad.shape[1] - 1] = 1\n",
    "        # pad[:, :, 0] = 1\n",
    "        # pad[:, :, pad.shape[2] - 1] = 1\n",
    "        #\n",
    "        # input = np.concatenate((input, np.expand_dims(pad, 1)), 1)\n",
    "\n",
    "        output = torch.from_numpy(output / 255.0).contiguous().float()\n",
    "        input = torch.from_numpy(input / 255.0).contiguous().float()\n",
    "        # print()\n",
    "        # print(input.size())\n",
    "        # print(output.size())\n",
    "\n",
    "        out = [idx,input,output]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_dataset = MovingMNIST(root='../', is_train=True, n_frames_output=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "idx = np.random.randint(len(train_dataset))\n",
    "example = train_dataset[idx]\n",
    "\n",
    "in_arr = example[1].numpy().reshape((-1, 64, 64))\n",
    "out_arr = example[2].numpy().reshape((-1, 64, 64))\n",
    "\n",
    "in_arr *= 255\n",
    "in_arr = in_arr.astype(np.uint8)\n",
    "\n",
    "out_arr *= 255\n",
    "out_arr = out_arr.astype(np.uint8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "Image.fromarray(np.concatenate(in_arr, axis=1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=640x64 at 0x7FB317D59150>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "Image.fromarray(np.concatenate(out_arr, axis=1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x7FB317D59590>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACFUlEQVR4nO2UP2gTcRTHv17uUlNy1hCDQR20mkLFQs0QalVsK1oy6FBKINBNFBd1qDhYDF1ExTrEpTiIuChFcFGhIBEshUK1QtBQa41O2qJIq4XYa9JvHLyUXHP587tBHO4zvXv3vu/77t7dD7CxsfmfadhXc+mG9Yn2gCcCz+7XyaG0Je89WepoX2sSyIar6Kk2B5IfAbRpjbPi9n3zTF7pdQHAJvcWt6jc3zuX521x2wKu68z/jiuW9f4RkufFdYU1yk+6gdFEFsD4u9VV8UZjLGKyZ7twg2EaSO8SbdD5IpXqUJRwV4uiNF9eypyrVVjyKQOAOrE3caw0HZCiXizEjEm5tA4INy0/XJc6vLk7cFQCMFZ9qJb+NN+3F2ckZ3yZZE7TenZ2llGph2L7vU6fzxeJ/SIXTxTfc10kmX070FrJdphkZlzfwZS/+JZ8n5y8erDK3PFcYYOZW2c9Bn0/eaO+rHBtCxcieKTWTwPPfhgrBmPA1u9V/CvQOE3O9JkstUYcz0mSK98GPKYbr4r8gWRqheSXHZYaSKHo3ZAaDN3UOGJlhLqgHmz8SR4wdajcwDujB0cWAQurOPlYLYSzZFh8go5Wpx4Frb3Cl7z292zqesX8vSazEtPzYI3TdzC3MDWBusEGzJ95Kj6B4/hn/Q9ZetAsLgcAaegNycTopXIFlR8BANzbgE85a/Y2NjY2/5Q/yEfa3UGvJdoAAAAASUVORK5CYII="
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('dev': conda)"
  },
  "interpreter": {
   "hash": "ab056dc25f0889fcb574ae6e472eade94d42e26aa4302f891626f1c166c36ce7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}